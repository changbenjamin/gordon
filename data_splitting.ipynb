{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a10d58-cda8-473a-aaee-abc044a823f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab7e129b-1082-48a1-81a5-8435836a057b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of PMIDs from date range: 5062\n",
      "\n",
      "Number of keys in biobert_embeddings_background.pkl: 11965\n",
      "\n",
      "Final list of PMIDs (in date range AND pickle keys):\n",
      "[37693474, 37503175, 37873372, 37397995, 37333385, 37398218, 37693450, 37131581, 37461514, 37645910, 37645984, 37333098, 37090601, 37502863, 37503048, 37066362, 37986845, 37163100, 37425947, 37425858, 37546986, 37425862, 37205393, 37503180, 37131640, 37904983, 37662226, 37503169, 37425961, 37292708, 37732194, 37577515, 37503223, 37645992, 37333072, 37961580, 37873401, 37066187, 37745351, 37425902, 37398038, 37873081, 37873229, 37873190, 37693601, 37781575, 37333142, 37662295, 37131582, 37425822, 37662341, 37745432, 37214825, 37808647, 37425758, 37214901, 37609260, 37645724, 37873175, 37215046, 37205432, 37905116, 37732274, 37873400, 37066370, 37693504, 37662217, 37745537, 37693549, 37662344, 37503031, 37732176, 37090679, 37398500, 37873491, 37732275, 37609345, 37503164, 37162924, 37034748, 37066302, 37873383, 37904955, 37425755, 37293032, 37425685, 37292845, 37886558, 37333277, 37503112, 37609265, 37662324, 37214836, 37546784, 37425672, 37066273, 37646001, 37662347, 37645960, 37745600]\n",
      "\n",
      "Number of PMIDs in final list: 100\n",
      "\n",
      "Number of PMIDs finally extracted (sampled up to 100): 100\n"
     ]
    }
   ],
   "source": [
    "# I'm taking out 100 papers from 2023 as my held-out test set, separate from the train-test split later on\n",
    "\n",
    "df = pd.read_csv('gordonramsay_data_processed.csv')\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%y')\n",
    "\n",
    "# Chose this range bc o1 train cutoff is October\n",
    "start_date = pd.to_datetime('2023-04-01')\n",
    "end_date = pd.to_datetime('2023-10-31')\n",
    "\n",
    "filtered_df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "\n",
    "pmids_series_date_filtered = filtered_df['PMID']\n",
    "pmid_list_date_filtered = pmids_series_date_filtered.tolist()\n",
    "\n",
    "print(f\"\\nNumber of PMIDs from date range: {len(pmid_list_date_filtered)}\")\n",
    "\n",
    "# Load the biobert_embeddings_background pickle file\n",
    "try:\n",
    "    with open('biobert_embeddings_background.pkl', 'rb') as f:\n",
    "        biobert_embeddings_background = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: biobert_embeddings_background.pkl file not found. Please check the file path.\")\n",
    "    exit()\n",
    "\n",
    "keys_in_pickle = biobert_embeddings_background.keys()\n",
    "print(f\"\\nNumber of keys in biobert_embeddings_background.pkl: {len(keys_in_pickle)}\")\n",
    "keys_in_pickle_set = set(keys_in_pickle)\n",
    "pmid_list_date_filtered_set = set(pmid_list_date_filtered)\n",
    "pmids_in_date_and_pickle_set = pmid_list_date_filtered_set.intersection(keys_in_pickle_set)\n",
    "\n",
    "pmid_list_final = list(pmids_in_date_and_pickle_set)\n",
    "\n",
    "num_samples_final = min(100, len(pmid_list_final))  # Ensure we don't sample more than available\n",
    "if pmid_list_final: # Only sample if there are PMIDs to sample from\n",
    "    sampled_pmid_list_final = random.sample(pmid_list_final, num_samples_final)\n",
    "else:\n",
    "    sampled_pmid_list_final = []\n",
    "\n",
    "    \n",
    "pmid_list = sampled_pmid_list_final\n",
    "\n",
    "print(\"\\nFinal list of PMIDs (in date range AND pickle keys):\")\n",
    "print(pmid_list)\n",
    "print(f\"\\nNumber of PMIDs in final list: {len(pmid_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71f0c84a-76e3-44ea-bfcb-e23cbbe85667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of llama3.1_embeddings_hypothesis.pkl: 11218\n",
      "\n",
      "Number of PMIDs found in llama3.1_embeddings_hypothesis: 100\n",
      "\n",
      "Length of llama_hypothesis_test.pkl: 100\n",
      "Length of llama_hypothesis_train.pkl: 11118\n"
     ]
    }
   ],
   "source": [
    "## Doing the train test split foor the hypothesis... I initially named everything as biobert but then refactored to be either\n",
    "\n",
    "pickle_name = 'llama3.1_embeddings_hypothesis'\n",
    "new_name = 'llama_hypothesis'\n",
    "\n",
    "with open(f'{pickle_name}.pkl', 'rb') as f:\n",
    "    biobert_embeddings_hypothesis = pickle.load(f)\n",
    "\n",
    "len_biobert_embeddings_hypothesis = len(biobert_embeddings_hypothesis)\n",
    "print(f\"Length of {pickle_name}.pkl: {len_biobert_embeddings_hypothesis}\")\n",
    "\n",
    "biobert_hypothesis_test_dict = {}\n",
    "\n",
    "found_pmids = 0 # Counter for found PMIDs\n",
    "\n",
    "for pmid in pmid_list:\n",
    "    if pmid in biobert_embeddings_hypothesis:\n",
    "        biobert_hypothesis_test_dict[pmid] = biobert_embeddings_hypothesis[pmid]\n",
    "        found_pmids += 1\n",
    "    else:\n",
    "        print(f\"  NOT FOUND PMID: {pmid}\")\n",
    "\n",
    "print(f\"\\nNumber of PMIDs found in {pickle_name}: {found_pmids}\") # Summary of found PMIDs\n",
    "\n",
    "with open(f'{new_name}_test.pkl', 'wb') as f:\n",
    "    pickle.dump(biobert_hypothesis_test_dict, f)\n",
    "\n",
    "with open(f'{new_name}_test.pkl', 'rb') as f:\n",
    "    biobert_hypothesis_test = pickle.load(f)\n",
    "\n",
    "len_biobert_hypothesis_test = len(biobert_hypothesis_test)\n",
    "print(f\"\\nLength of {new_name}_test.pkl: {len_biobert_hypothesis_test}\")\n",
    "\n",
    "biobert_hypothesis_train_dict = {}\n",
    "pmid_set_test = set(biobert_hypothesis_test_dict.keys())\n",
    "\n",
    "for pmid, embedding in biobert_embeddings_hypothesis.items():\n",
    "    if pmid not in pmid_set_test:\n",
    "        biobert_hypothesis_train_dict[pmid] = embedding\n",
    "\n",
    "with open(f'{new_name}_train.pkl', 'wb') as f:\n",
    "    pickle.dump(biobert_hypothesis_train_dict, f)\n",
    "\n",
    "len_biobert_hypothesis_train = len(biobert_hypothesis_train_dict)\n",
    "print(f\"Length of {new_name}_train.pkl: {len_biobert_hypothesis_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4cbb59a-bda1-4bdc-ba74-359052604333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are keys in biobert_hypothesis_test.pkl the same as pmid_list?: True\n",
      "Are there repeats in keys of biobert_hypothesis_test.pkl?: False\n"
     ]
    }
   ],
   "source": [
    "# It's super important that the split worked correctly, so double checking here\n",
    "\n",
    "with open('llama_hypothesis_test.pkl', 'rb') as f:\n",
    "    biobert_hypothesis_test = pickle.load(f)\n",
    "\n",
    "keys_in_test_pickle = set(biobert_hypothesis_test.keys())\n",
    "pmid_list_set = set(pmid_list)\n",
    "\n",
    "same_keys = keys_in_test_pickle == pmid_list_set\n",
    "no_repeats_in_pickle_keys = len(keys_in_test_pickle) == len(biobert_hypothesis_test)\n",
    "\n",
    "print(f\"Are keys in this test pkl the same as pmid_list?: {same_keys}\")\n",
    "print(f\"Are there repeats in keys of this test pkl?: {not no_repeats_in_pickle_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee4346f-28ba-4634-833a-9f8d0657e2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random background test set embeddings...\n",
      "Inferred embedding dimension from biobert_background_train.pkl: 1024\n",
      "Number of PMIDs from biobert_background_train.pkl: 11865\n",
      "Generating random embeddings...\n",
      "Generated 11865 random embeddings.\n",
      "Saving random embeddings to: random_background_train.pkl\n",
      "Random embedding file generated successfully: random_background_train.pkl\n",
      "Generating random hypothesis test set embeddings...\n",
      "Inferred embedding dimension from biobert_background_train.pkl: 1024\n",
      "Number of PMIDs from biobert_background_train.pkl: 11865\n",
      "Generating random embeddings...\n",
      "Generated 11865 random embeddings.\n",
      "Saving random embeddings to: random_hypothesis_train.pkl\n",
      "Random embedding file generated successfully: random_hypothesis_train.pkl\n",
      "Random embedding files for test set generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Generating random embeddings based on the same PMIDs from actual embeddings\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "output_background_pkl = 'random_background_train.pkl'\n",
    "output_hypothesis_pkl = 'random_hypothesis_train.pkl'\n",
    "input_biobert_background_pkl = 'biobert_background_train.pkl'\n",
    "\n",
    "\n",
    "def generate_random_embeddings_from_biobert(input_biobert_pkl_file, output_pkl_file):\n",
    "    \"\"\"\n",
    "    Generates a dictionary of random embeddings using PMIDs and embedding dimension\n",
    "    from an existing BioBERT embeddings pickle file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_biobert_pkl_file, 'rb') as f:\n",
    "            biobert_embeddings_dict = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input BioBERT embeddings file not found: {input_biobert_pkl_file}\")\n",
    "        return None\n",
    "\n",
    "    pmid_list = list(biobert_embeddings_dict.keys())\n",
    "    if not pmid_list:\n",
    "        print(f\"Error: No PMIDs found in input BioBERT embeddings file: {input_biobert_pkl_file}\")\n",
    "        return None\n",
    "\n",
    "    example_embedding = biobert_embeddings_dict[pmid_list[0]]\n",
    "    embedding_dim = len(example_embedding)\n",
    "    print(f\"Inferred embedding dimension from {input_biobert_pkl_file}: {embedding_dim}\")\n",
    "    print(f\"Number of PMIDs from {input_biobert_pkl_file}: {len(pmid_list)}\")\n",
    "\n",
    "    print(\"Generating random embeddings...\")\n",
    "    random_embeddings_dict = {}\n",
    "    for pmid in pmid_list:\n",
    "        random_embedding = np.random.rand(embedding_dim).tolist()\n",
    "        random_embeddings_dict[pmid] = random_embedding\n",
    "    print(f\"Generated {len(random_embeddings_dict)} random embeddings.\")\n",
    "\n",
    "    print(f\"Saving random embeddings to: {output_pkl_file}\")\n",
    "    with open(output_pkl_file, 'wb') as f:\n",
    "        pickle.dump(random_embeddings_dict, f)\n",
    "\n",
    "    print(f\"Random embedding file generated successfully: {output_pkl_file}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Generating random background test set embeddings...\")\n",
    "    generate_random_embeddings_from_biobert(input_biobert_background_pkl, output_background_pkl)\n",
    "\n",
    "    print(\"Generating random hypothesis test set embeddings...\")\n",
    "    generate_random_embeddings_from_biobert(input_biobert_background_pkl, output_hypothesis_pkl)\n",
    "\n",
    "    print(\"Random embedding files for test set generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497be28e-49bf-4ea9-a5f4-c91d4fa6c77d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juniper",
   "language": "python",
   "name": "juniper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
